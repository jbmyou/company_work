{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0d717ef",
   "metadata": {},
   "source": [
    "#### import 및 기본변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab1463d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "신복 특별면책, 반송 확인 후 전산 바로 수정!\n",
      "개회 엑셀 받은 후 최근 면책건 채무/보증인 상태값만 바로 수정(담당자x)\n",
      "채무자 다운 후 1. 법인의 채무상태 확인 및 수정-법인도 채무상태로 일단 새채무상태 작성함\n",
      "계좌 다운 후 2. 담당자 종결, 매각, 환매, ds인데 종결일 없는 건 확인 및 수정\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, os, functions\n",
    "from os.path import join\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "debt_dtype = {'채무자키':str, '타채무자키':str, '담당자키':str, '관리자비고':str}\n",
    "account_dtype = {'채무자키':str, '계좌키':str, '타채무자키':str}\n",
    "grt_dtype = {'채무자키':str, '계좌키':str, '타채무자키':str, '보증인키':str}\n",
    "rehabilitation_dtype = {'채무자키':str, '계좌키':str, '분납키':str, '사건키':str, '신고계좌':str, '입금계좌':str}\n",
    "credit_dtype = {\"채무자키\":str, \"계좌키\":str, '보증인키':str, '신용회복키' : str, \"계좌번호\":str, \"심의차수\":str, \"변제금수취계좌\":str}\n",
    "event_dtype = {'채무자키':str, '법조치키':str, '계좌키':str, '관련법조치키':str, '법취하키':str, '타법조치키':str, '타채무자키':str, '관할법원코드':str}\n",
    "deposit_dtype = {'채무자키':str, '입금키':str, '계좌키':str, '계좌번호':str, '입금고정키':str, '타채무자키':str}\n",
    "reduction_dtype = {'채무자키':str, '계좌키':str, '감면키':str}\n",
    "installment_dtype = {'채무자키':str, '계좌키':str, '분납키':str}\n",
    "\n",
    "##################################\n",
    "company = \"솔림\"      # 솔림 or 대성\n",
    "basedate = \"250824\" \n",
    "previous_cutoff = \"250731\" # 계좌 \n",
    "wd = join(r\"D:\\3.자산\\전산 dataset\", company)\n",
    "##################################\n",
    "ext = \".xlsx\"  \n",
    "read_dir = join(wd, basedate)\n",
    "write_dir = join(wd, basedate, \"parquet\")\n",
    "previous_read_dir = join(wd, previous_cutoff, \"parquet\")\n",
    "\n",
    "# parquet 폴더 만들기\n",
    "if not os.path.exists(write_dir) :\n",
    "    os.makedirs(write_dir)\n",
    "\n",
    "\n",
    "# 작업전 할일 ################################\n",
    "\"\"\"\n",
    "모든 데이터 다운받기 전에\n",
    "아래 내용 사전점검 할 것! 이것만 해둬도 파일 다운 받고 기준데이터 만들어도 될듯?\n",
    "\"\"\"\n",
    "print('신복 특별면책, 반송 확인 후 전산 바로 수정!')\n",
    "print('개회 엑셀 받은 후 최근 면책건 채무/보증인 상태값만 바로 수정(담당자x)')\n",
    "print('채무자 다운 후 1. 법인의 채무상태 확인 및 수정-법인도 채무상태로 일단 새채무상태 작성함')\n",
    "print('계좌 다운 후 2. 담당자 종결, 매각, 환매, ds인데 종결일 없는 건 확인 및 수정')\n",
    "\n",
    "\n",
    "\n",
    "# 1) object 컬럼 → str\n",
    "# for col in df.select_dtypes(include='object').columns:\n",
    "#     df[col] = df[col].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0485f12c",
   "metadata": {},
   "source": [
    "#### 개인회생"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7e5a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 엑셀 읽기, 정렬(사건-컷오프-채권번호), parquet 저장\n",
    "filename = functions.키워드로파일명찾기(read_dir, \"개인회생새창\", \"기준데이터\", 전체경로=False).split('.')[0]\n",
    "df = pd.read_excel(join(read_dir, filename+\".xlsx\"), dtype=rehabilitation_dtype).fillna(\"\")\n",
    "\n",
    "# 진행내용 표시 했는지 체크\n",
    "if df.loc[0,\"진행내용\"] == \"\" :\n",
    "    print(\"개인회생 엑셀다운로드시 우클릭후 '1.채권자목록,일반내용,진행내용 표시'를 선택해야 합니다.\")\n",
    "\n",
    "# parquet 저장\n",
    "functions.to_parquet(df, join(write_dir, filename+\".parquet\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06e4e7d",
   "metadata": {},
   "source": [
    "#### 전산 raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee9c085",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy._core.numeric'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DATA\\AppData\\Local\\anaconda3\\envs\\py_312\\Lib\\site-packages\\pandas\\io\\pickle.py:202\u001b[39m, in \u001b[36mread_pickle\u001b[39m\u001b[34m(filepath_or_buffer, compression, storage_options)\u001b[39m\n\u001b[32m    201\u001b[39m         warnings.simplefilter(\u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;167;01mWarning\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpickle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandles\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m excs_to_catch:\n\u001b[32m    204\u001b[39m     \u001b[38;5;66;03m# e.g.\u001b[39;00m\n\u001b[32m    205\u001b[39m     \u001b[38;5;66;03m#  \"No module named 'pandas.core.sparse.series'\"\u001b[39;00m\n\u001b[32m    206\u001b[39m     \u001b[38;5;66;03m#  \"Can't get attribute '__nat_unpickle' on <module 'pandas._libs.tslib\"\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'numpy._core.numeric'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m      4\u001b[39m 파일검색어 = { \u001b[38;5;66;03m# [타입, 제외키워드]\u001b[39;00m\n\u001b[32m      5\u001b[39m \n\u001b[32m      6\u001b[39m     \u001b[38;5;66;03m# \"입금조회.*당월\" : [deposit_dtype,\"\"],\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m     \u001b[38;5;66;03m# \"약정분납새창\" : [installment_dtype,\"기준데이터\"]\u001b[39;00m\n\u001b[32m     16\u001b[39m }\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m#########################################\u001b[39;00m\n\u001b[32m     18\u001b[39m \n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# 이전계좌 (종결확인)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m account_previous = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m.\u001b[49m\u001b[43m키워드로파일명찾기\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprevious_read_dir\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m포함키워드\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m계좌조회새창\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m전체경로\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# 계좌, 보증인새창 읽을 때면 채무상태 누락건 없는지 미리 확인\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33m계좌조회\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m 파일검색어.keys()) \u001b[38;5;129;01mor\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33m보증인새창\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m 파일검색어.keys()) :\n\u001b[32m     25\u001b[39m     \u001b[38;5;66;03m# 상태정리파일\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DATA\\AppData\\Local\\anaconda3\\envs\\py_312\\Lib\\site-packages\\pandas\\io\\pickle.py:207\u001b[39m, in \u001b[36mread_pickle\u001b[39m\u001b[34m(filepath_or_buffer, compression, storage_options)\u001b[39m\n\u001b[32m    202\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m pickle.load(handles.handle)\n\u001b[32m    203\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m excs_to_catch:\n\u001b[32m    204\u001b[39m         \u001b[38;5;66;03m# e.g.\u001b[39;00m\n\u001b[32m    205\u001b[39m         \u001b[38;5;66;03m#  \"No module named 'pandas.core.sparse.series'\"\u001b[39;00m\n\u001b[32m    206\u001b[39m         \u001b[38;5;66;03m#  \"Can't get attribute '__nat_unpickle' on <module 'pandas._libs.tslib\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m207\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandles\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mUnicodeDecodeError\u001b[39;00m:\n\u001b[32m    209\u001b[39m     \u001b[38;5;66;03m# e.g. can occur for files written in py27; see GH#28645 and GH#31988\u001b[39;00m\n\u001b[32m    210\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m pc.load(handles.handle, encoding=\u001b[33m\"\u001b[39m\u001b[33mlatin-1\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DATA\\AppData\\Local\\anaconda3\\envs\\py_312\\Lib\\site-packages\\pandas\\compat\\pickle_compat.py:231\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(fh, encoding, is_verbose)\u001b[39m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# \"Unpickler\" has no attribute \"is_verbose\"  [attr-defined]\u001b[39;00m\n\u001b[32m    229\u001b[39m     up.is_verbose = is_verbose  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mup\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[32m    233\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DATA\\AppData\\Local\\anaconda3\\envs\\py_312\\Lib\\pickle.py:1256\u001b[39m, in \u001b[36m_Unpickler.load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1254\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m\n\u001b[32m   1255\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, bytes_types)\n\u001b[32m-> \u001b[39m\u001b[32m1256\u001b[39m         \u001b[43mdispatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1257\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _Stop \u001b[38;5;28;01mas\u001b[39;00m stopinst:\n\u001b[32m   1258\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m stopinst.value\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DATA\\AppData\\Local\\anaconda3\\envs\\py_312\\Lib\\pickle.py:1581\u001b[39m, in \u001b[36m_Unpickler.load_stack_global\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1579\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(name) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mstr\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(module) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m   1580\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m UnpicklingError(\u001b[33m\"\u001b[39m\u001b[33mSTACK_GLOBAL requires str\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1581\u001b[39m \u001b[38;5;28mself\u001b[39m.append(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfind_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DATA\\AppData\\Local\\anaconda3\\envs\\py_312\\Lib\\site-packages\\pandas\\compat\\pickle_compat.py:162\u001b[39m, in \u001b[36mUnpickler.find_class\u001b[39m\u001b[34m(self, module, name)\u001b[39m\n\u001b[32m    160\u001b[39m key = (module, name)\n\u001b[32m    161\u001b[39m module, name = _class_locations_map.get(key, key)\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfind_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DATA\\AppData\\Local\\anaconda3\\envs\\py_312\\Lib\\pickle.py:1622\u001b[39m, in \u001b[36m_Unpickler.find_class\u001b[39m\u001b[34m(self, module, name)\u001b[39m\n\u001b[32m   1620\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m _compat_pickle.IMPORT_MAPPING:\n\u001b[32m   1621\u001b[39m         module = _compat_pickle.IMPORT_MAPPING[module]\n\u001b[32m-> \u001b[39m\u001b[32m1622\u001b[39m \u001b[38;5;28;43m__import__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1623\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.proto >= \u001b[32m4\u001b[39m:\n\u001b[32m   1624\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _getattribute(sys.modules[module], name)[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'numpy._core.numeric'"
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "세부주소 = False # 상세주소 제외할지 모두 포함할지(기본값 False)\n",
    "# 초본 > 자택 > 직장 > 기타 우선순위 적용은 항상 한다.\n",
    "파일검색어 = { # [타입, 제외키워드]\n",
    "         \n",
    "    # \"입금조회.*당월\" : [deposit_dtype,\"\"],\n",
    "    \n",
    "    # \"계좌조회\" : [account_dtype,\"\"],\n",
    "    # \"보증인새창\" : [grt_dtype,\"새보증인상태\"],\n",
    "    \n",
    "    # \"채무자조회\" : [debt_dtype,\"\"],\n",
    "    # \"법조치조회\" : [event_dtype,\"\"],\n",
    "    \n",
    "    \"감면조회\" : [reduction_dtype,\"\"],\n",
    "    # \"약정분납새창\" : [installment_dtype,\"기준데이터\"]\n",
    "}\n",
    "#########################################\n",
    "\n",
    "# 이전계좌 (종결확인)\n",
    "account_previous = pd.read_pickle(functions.키워드로파일명찾기(join(previous_read_dir), 포함키워드=\"계좌조회새창\", 전체경로=True))\n",
    "\n",
    "\n",
    "# 계좌, 보증인새창 읽을 때면 채무상태 누락건 없는지 미리 확인\n",
    "if (\"계좌조회\" in 파일검색어.keys()) or (\"보증인새창\" in 파일검색어.keys()) :\n",
    "    # 상태정리파일\n",
    "    path_상태정리 = r\"D:\\3.자산\\전산 dataset\\상태정리.xlsx\"\n",
    "    상태정리 = pd.read_excel(path_상태정리, sheet_name=\"상태\", header=1)\n",
    "    메모정리 = pd.read_excel(path_상태정리, sheet_name=\"메모\")\n",
    "    담당자정리 = pd.read_excel(path_상태정리, sheet_name=\"담당자\")\n",
    "\n",
    "    \n",
    "for i, v in 파일검색어.items() : \n",
    "    print(i, '파일변환시작')\n",
    "    filename = os.path.splitext(functions.키워드로파일명찾기(read_dir, i, v[1],전체경로=False))[0]\n",
    "    df = pd.read_excel(join(wd, basedate, filename+ext), dtype = v[0]).fillna(\"\")\n",
    "    \n",
    "    # 1) 상태정리에 없는 상태값 확인(있으면 상태정리 파일 업데이트 해야! 수정건 있으면 break)\n",
    "    # 2) 담당자와 메모가 종결값인데 종결일 없는 경우\n",
    "    if re.search(\"계좌|보증인\", i) :\n",
    "        if re.search(\"계좌\", i) : \n",
    "            상태칼럼명 = \"채무상태\"\n",
    "            출력cols = [\"채무자키\",\"계좌키\", 상태칼럼명, \"담당자\",\"종결일\"]\n",
    "            \n",
    "            # 종결해제건 확인 -----\n",
    "            전달종결건 = account_previous[account_previous.종결일!=\"\"][\"계좌키\"]\n",
    "            종결해제건 = df[(df.종결일==\"\") & df.계좌키.isin(전달종결건)][출력cols]\n",
    "            if not 종결해제건.empty :\n",
    "                functions.display_with_explain(종결해제건, \"종결해제건\")\n",
    "            \n",
    "            \n",
    "        else : \n",
    "            상태칼럼명 = \"보증인상태\"\n",
    "            출력cols = [\"채무자키\",\"계좌키\",\"보증인키\", 상태칼럼명, \"담당자\",\"종결일\"]\n",
    "        \n",
    "        미종결조건 = (df[\"종결일\"]==\"\") # fillna('')했음\n",
    "        \n",
    "        # 상태정리에 없는 상태값 확인\n",
    "        상태수정할건 = df[미종결조건 & (~df[상태칼럼명].str.replace(\"_\",\"\").isin(상태정리.채무상태)|(df[상태칼럼명]==\"\"))]\n",
    "        if not 상태수정할건.empty : \n",
    "            functions.display_with_explain(상태수정할건[출력cols], \"상태정리에 없는 상태값 확인\")\n",
    "\n",
    "    \n",
    "    # 채무자 관리자비고(새채무자키) 검사\n",
    "    if re.search(\"채무자\", i) :\n",
    "        if len(df.query(\"관리자비고==''\")) > 1 :\n",
    "            print(\"새채무자키 부여 필요\")\n",
    "            print(len(nothing)) # 오류를 위한 코드\n",
    "        \n",
    "        # 예수금제외\n",
    "        df.drop(df[(df.성명==\"예수금\")].index, inplace=True)\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        # 채무자 주소 보정  \n",
    "        cols = [\"초본주소\", \"초본번지인\", \"초본우편번호\", \"자택주소\",\"자택번지인\",\"자택우편번호\",\"직장주소\",\"직장번지인\", \"직장우편번호\",\"기타주소\", \"기타번지인\", \"기타우편번호\"]\n",
    "        df[cols] = df[cols].applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "\n",
    "        # 주소채우기 : 초본이 없는 경우 자택 > 직장 > 기타 주소를 초본칸에 넣기\n",
    "            # values를 붙이거나 to_numpy()를 붙여야함.(안그럼 정렬과 인덱스유지 사이의 충돌로 na값이 입력됨)\n",
    "            # 이제 isna()조건은 없어도 되지만 혹시 몰라서 추가함\n",
    "        mask = ((df.초본주소==\"\") | (df.초본주소.isna()))\n",
    "        df.loc[mask,[\"초본주소\", \"초본번지인\", \"초본우편번호\"]] = df.loc[mask, [\"자택주소\", \"자택번지인\", \"자택우편번호\"]].to_numpy()\n",
    "        mask = ((df.초본주소==\"\") | (df.초본주소.isna()))\n",
    "        df.loc[mask,[\"초본주소\", \"초본번지인\", \"초본우편번호\"]] = df.loc[mask, [\"직장주소\", \"직장번지인\", \"직장우편번호\"]].to_numpy()\n",
    "        mask = ((df.초본주소==\"\") | (df.초본주소.isna()))\n",
    "        df.loc[mask,[\"초본주소\", \"초본번지인\", \"초본우편번호\"]] = df.loc[mask, [\"기타주소\", \"기타번지인\", \"기타우편번호\"]].to_numpy()\n",
    "    \n",
    "    # 계좌 예수금 제거\n",
    "    if re.search(\"계좌\", i) :\n",
    "        df.drop(df[(df.채무자명==\"예수금\")].index, inplace=True)\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "    # 법조치 법원사건번호 없는 것 제거\n",
    "    if re.search('법조치', i) :\n",
    "        index =  df[(df.관할법원==\"0\") | (df.관할법원==\"\") | (df.사건번호==\"0\") | (df.사건번호==\"\")].index\n",
    "        df.drop(index, inplace=True)\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        # 사건번호 역순정렬\n",
    "        df.sort_values('사건번호', ascending=False, inplace=True)\n",
    "    \n",
    "    # parquet 저장\n",
    "    functions.to_parquet(df, join(write_dir, filename+\".parquet\"), engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ed343b",
   "metadata": {},
   "source": [
    "#### 신용회복 계좌별진행상황"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfa7c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 계좌별 진행상황 파일 읽기\n",
    "########################################################\n",
    "약식병합 = False ############# 금요일(일요일)이 컷오프가 아니라면 약식병합해야-------\n",
    "basedate = basedate # \"250423\" # 정식 업로드결과 파일 날짜 컷오프일에 맞춰 수정\n",
    "company = company  # 솔림 or 대성\n",
    "########################################################\n",
    "\n",
    "nauri_dtype = {\"채무자키\":str, \"계좌키\":str, '보증인키':str, '신용회복키' : str, \"계좌번호\":str, \"심의차수\":str, \"변제금수취계좌\":str}\n",
    "path_base = r\"D:\\3.자산\\신용회복\\신용회복 전체데이터\\계좌별 진행상황\"\n",
    "\n",
    "# parquet 폴더 없으면 만들기\n",
    "write_path_base = join(path_base, \"parquet\")\n",
    "if not os.path.exists(write_path_base) :\n",
    "    os.mkdir(write_path_base)\n",
    "\n",
    "# 읽을 파일명\n",
    "suffix = \"통합\" if company!=\"대성\" else \"대성\"\n",
    "\n",
    "filename = basedate + \"_계좌별 진행상황 조회_\" + suffix\n",
    "\n",
    "filename_정식 = filename + \"_업로드결과\"\n",
    "filename_약식 = filename + \"_약식_업로드결과\"\n",
    "\n",
    "# 계좌별 진행상황 조회 파일 읽기 및 parquet 저장\n",
    "    # 정식\n",
    "정식_ori = pd.read_excel(join(path_base, filename_정식+\".xlsx\" ), dtype=nauri_dtype).fillna(\"\")\n",
    "functions.to_parquet(정식_ori, join(write_path_base, filename_정식+\".parquet\"))\n",
    "    # 약식\n",
    "if 약식병합 : \n",
    "    약식_ori = pd.read_excel(join(path_base, filename_약식+\".xlsx\"), dtype=nauri_dtype).fillna(\"\")\n",
    "    functions.to_parquet(약식_ori, join(write_path_base, filename_약식+\".parquet\"))\n",
    "\n",
    "# 이건 기준데이터 아니니 파일 옮길 필요 없음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be248951",
   "metadata": {},
   "source": [
    "### 기타"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9067ac",
   "metadata": {},
   "source": [
    "#### 단일파일"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406d5575",
   "metadata": {},
   "source": [
    "#### 폴더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42232f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "변환시작 : 감면율로그_~250630.xlsx\n",
      "변환시작 : 상환후잔액로그_~250630.xlsx\n",
      "변환시작 : 신청인진행상태로그_~250630.xlsx\n",
      "변환시작 : 접수번호로그_~250630.xlsx\n",
      "변환시작 : 합의서체결일로그_~250630.xlsx\n"
     ]
    }
   ],
   "source": [
    "##########################################################\n",
    "path_read = r\"D:\\3.자산\\전산 dataset\\솔림\\기간축적데이터\\신용회복\"\n",
    "dtype_to_use = credit_dtype\n",
    "##########################################################\n",
    "p_extension = re.compile('xlsx$', re.I)\n",
    "file_list = [f.name for f in os.scandir(path_read) if f.is_file() and p_extension.search(f.name)]\n",
    "\n",
    "for f in file_list :\n",
    "    print(\"변환시작 :\",f)\n",
    "    fn = os.path.splitext(f)[0]\n",
    "    df = pd.read_excel(join(path_read, f), dtype=dtype_to_use)\n",
    "    functions.to_parquet(df, join(path_read, \"parquet\", fn+\".parquet\"), engine=\"pyarrow\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
